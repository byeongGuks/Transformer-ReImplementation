{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DMIS\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(\"iwslt2017\", 'iwslt2017-de-en', cache_dir='./data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def make_dataset(file_path, docs) :\n",
    "    f = open(file_path, \"w\", encoding='utf-8')\n",
    "    for doc in docs :\n",
    "        segs = doc.findall('seg')\n",
    "        for seg in segs :\n",
    "            text = seg.text.lower()\n",
    "            try :\n",
    "                f.write(text)\n",
    "                f.write('\\n')\n",
    "            except : \n",
    "                print(text)\n",
    "    f.close()\n",
    "\n",
    "train_folder_path = \"./data/de-en/training_and_development/\"\n",
    "test_folder_path = \"./data/de-en/test/\"\n",
    "\n",
    "## train english\n",
    "tree_en = ET.parse(train_folder_path + 'IWSLT17.TED.dev2010.de-en.en.xml')\n",
    "root_en = tree_en.getroot()\n",
    "refset = root_en.find('refset')\n",
    "docs = refset.findall('doc')\n",
    "make_dataset(\"./data/de-en/train.en\", docs)\n",
    "\n",
    "## train deutsch\n",
    "tree_de = ET.parse(train_folder_path + \"IWSLT17.TED.dev2010.de-en.de.xml\")\n",
    "root_de = tree_de.getroot()\n",
    "srcset = root_de.find('srcset')\n",
    "docs = srcset.findall('doc')\n",
    "make_dataset(\"./data/de-en/train.de\", docs)\n",
    "\n",
    "## test en\n",
    "tree_en_test = ET.parse(test_folder_path + 'IWSLT17.TED.tst2017.mltlng.en-de.en.xml')\n",
    "root_en_test = tree_en_test.getroot()\n",
    "srcset = root_en_test.find('srcset')\n",
    "docs = srcset.findall('doc')\n",
    "make_dataset(\"./data/de-en/test.en\", docs)\n",
    "\n",
    "## test deutsch\n",
    "tree_de_test = ET.parse(test_folder_path + 'IWSLT17.TED.tst2017.mltlng.de-en.de.xml')\n",
    "root_de_test = tree_de_test.getroot()\n",
    "srcset = root_de_test.find('srcset')\n",
    "docs = srcset.findall('doc')\n",
    "make_dataset(\"./data/de-en/test.de\", docs)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "train_folder_path = \"./data/de-en/training_and_development/\"\n",
    "test_folder_path = \"./data/de-en/test/\"\n",
    "\n",
    "## train english\n",
    "tree_en = ET.parse(train_folder_path + 'IWSLT17.TED.dev2010.de-en.en.xml')\n",
    "root_en = tree_en.getroot()\n",
    "refset = root_en.find('refset')\n",
    "docs = refset.findall('doc')\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Vocabulary : BPE Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'o', 'w', '</w>']\n",
      "['l', 'o', 'w', 'e', 'r', '</w>']\n",
      "['n', 'e', 'w', 'e', 's', 't', '</w>']\n",
      "['w', 'i', 'd', 'e', 's', 't', '</w>']\n",
      "['l', 'o', 'w', '']\n",
      "['l', 'o', 'w', 'e', 'r', '']\n",
      "['n', 'e', 'w', 'es', 't', '']\n",
      "['w', 'i', 'd', 'es', 't', '']\n",
      "['l', 'o', 'w', '']\n",
      "['l', 'o', 'w', 'e', 'r', '']\n",
      "['n', 'e', 'w', 'est', '']\n",
      "['w', 'i', 'd', 'est', '']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m#file_path = 'C://Users/DMIS/project/transformer/data/de-en/train.en'\u001b[39;00m\n\u001b[0;32m     81\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC://Users/DMIS/project/transformer/data/de-en/bpe_ex.en\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 83\u001b[0m byte_pair_encoding(file_path, \u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[31], line 76\u001b[0m, in \u001b[0;36mbyte_pair_encoding\u001b[1;34m(file_path, count)\u001b[0m\n\u001b[0;32m     74\u001b[0m vocabulary[frontword \u001b[39m+\u001b[39m backword] \u001b[39m=\u001b[39m max_count\n\u001b[0;32m     75\u001b[0m vocabulary[frontword] \u001b[39m=\u001b[39m vocabulary[frontword] \u001b[39m-\u001b[39m max_count\n\u001b[1;32m---> 76\u001b[0m vocabulary[backword] \u001b[39m=\u001b[39m vocabulary[backword] \u001b[39m-\u001b[39m max_count\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "## return (maximum counted pair, count)\n",
    "## ex - (h st, 10)\n",
    "def search_max_pair(dict) :\n",
    "    pair_count = {}\n",
    "    \n",
    "    ## pair count\n",
    "    for word in dict:\n",
    "        unit_list = word.split(' ')\n",
    "        count_of_word = dict[word] \n",
    "        print(unit_list)\n",
    "        for i in range(len(unit_list) - 1):\n",
    "            new_word = unit_list[i] + ' ' + unit_list[i+1] ## insert space for distinguish frontword and backword\n",
    "            pair_count[new_word] = pair_count[new_word] + count_of_word if (new_word in pair_count) else count_of_word\n",
    "    ## search maximum pair\n",
    "    max_count = 0\n",
    "    max_pair = ''\n",
    "    for pair in pair_count:\n",
    "        if pair_count[pair] > max_count :\n",
    "            max_count = pair_count[pair]\n",
    "            max_pair = pair\n",
    "    return (max_pair, max_count)\n",
    "\n",
    "def merge_word_dict(dict, frontword, backword) :\n",
    "    new_word_dict = {}\n",
    "    for word in dict :\n",
    "        unit_list = word.split(' ')\n",
    "        new_word = ''\n",
    "        i=0\n",
    "        while i < len(unit_list)-1 :\n",
    "            if unit_list[i] != frontword or unit_list[i+1] != backword : \n",
    "                new_word = new_word + unit_list[i] + ' '\n",
    "            else :\n",
    "                new_word = new_word + unit_list[i] + unit_list[i+1] + ' '\n",
    "                i += 1 ## skip next unit\n",
    "            i += 1\n",
    "        new_word_dict[new_word] = dict[word] ## change word with new key\n",
    "    return new_word_dict\n",
    "                \n",
    "                \n",
    "        \n",
    "\n",
    "def byte_pair_encoding(file_path, count=10) : \n",
    "    f = open(file_path, \"r\", encoding='utf-8')\n",
    "    stop_word_set = set([',', ' ', '-', '', '\\n', '.', '!'])\n",
    "    word_dict = {}  ## key-bpe encoded words / value-count : word set for calculate maximun counted pair\n",
    "    vocabulary = {} ## key-vacab word / value-count : vocabulary for encoding, \n",
    "    while True :\n",
    "        line = f.readline()\n",
    "        if not line :\n",
    "            break\n",
    "        \n",
    "        words = line.split(' ')\n",
    "        for word in words :\n",
    "            word = re.sub('[,\\-\\n!]', '', word)\n",
    "            if word not in stop_word_set :\n",
    "                splited_word = ''\n",
    "                for character in [*word]:\n",
    "                    splited_word = splited_word + character + ' '\n",
    "                    vocabulary[character] = vocabulary[character] + 1 if (character in vocabulary) else 1\n",
    "                splited_word = splited_word + '</w>'\n",
    "                word_dict[splited_word] = word_dict[splited_word] + 1 if (splited_word in word_dict) else 1\n",
    "\n",
    "    for i in range(count) :\n",
    "        #print(vocabulary)\n",
    "        #print(word_dict)\n",
    "        max_pair, max_count = search_max_pair(word_dict)\n",
    "        subwords = max_pair.split(' ')\n",
    "        frontword = subwords[0]\n",
    "        backword = subwords[1]\n",
    "        \n",
    "        word_dict = merge_word_dict(word_dict, frontword=frontword, backword=backword)\n",
    "        vocabulary[frontword + backword] = max_count\n",
    "        vocabulary[frontword] = vocabulary[frontword] - max_count\n",
    "        vocabulary[backword] = vocabulary[backword] - max_count\n",
    "        \n",
    "        \n",
    "        \n",
    "#file_path = 'C://Users/DMIS/project/transformer/data/de-en/train.en'\n",
    "file_path = 'C://Users/DMIS/project/transformer/data/de-en/bpe_ex.en'\n",
    "\n",
    "byte_pair_encoding(file_path, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(vocabulary)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocabulary' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
